2021-10-07 17:15:02.288605
['/Users/kunyang/PycharmProjects/kjl/examples/offline/deployment', '/Users/kunyang/PycharmProjects/kjl', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python37.zip', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/lib-dynload', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/Keras-2.3.1-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/PyYAML-5.2-py3.7-macosx-10.14-x86_64.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/Keras_Preprocessing-1.1.0-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/Keras_Applications-1.0.8-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/h5py-2.10.0-py3.7-macosx-10.14-x86_64.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/Werkzeug-0.16.0-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/requests-2.22.0-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/protobuf-3.11.1-py3.7-macosx-10.14-x86_64.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/Markdown-3.1.1-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/grpcio-1.25.0-py3.7-macosx-10.14-x86_64.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/google_auth-1.7.1-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/google_auth_oauthlib-0.4.1-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/absl_py-0.8.1-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/wrapt-1.11.2-py3.7-macosx-10.14-x86_64.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/termcolor-1.1.0-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/opt_einsum-3.1.0-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/google_pasta-0.1.8-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/astor-0.8.0-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/numba-0.46.0-py3.7-macosx-10.14-x86_64.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/pytz-2019.3-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/python_dateutil-2.8.1-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/urllib3-1.25.7-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/idna-2.8-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/chardet-3.0.4-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/certifi-2019.11.28-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/rsa-4.0-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/pyasn1_modules-0.2.7-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/cachetools-3.1.1-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/requests_oauthlib-1.3.0-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/llvmlite-0.30.0-py3.7-macosx-10.14-x86_64.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/pyparsing-2.4.5-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/kiwisolver-1.1.0-py3.7-macosx-10.14-x86_64.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/cycler-0.10.0-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/pyasn1-0.4.8-py3.7.egg', '/Users/kunyang/Library/Python/3.7/lib/python/site-packages/oauthlib-3.1.0-py3.7.egg', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages', '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/extensions']
/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.neighbors.kde module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.
  warnings.warn(message, FutureWarning)
2021-10-07 17:15:06.138 | DEBUG    | examples.offline.offline:<module>:38 - DATASETS: ['UNB3_345', 'CTU1', 'MAWI1_2020', 'MACCDC1', 'SFRIG1_2021', 'AECHO1_2020', 'DWSHR_AECHO_2020'], FEATURES: ['IAT+SIZE', 'STATS'], HEADERS: [False, True], MODELS: ['OCSVM(rbf)', 'KJL-OCSVM(linear)', 'Nystrom-OCSVM(linear)', 'KJL-GMM(full)', 'KJL-GMM(diag)', 'Nystrom-GMM(full)', 'Nystrom-GMM(diag)', 'KJL-QS-GMM(full)', 'KJL-QS-GMM(diag)', 'Nystrom-QS-GMM(full)', 'Nystrom-QS-GMM(diag)'], TUNINGS: [False, True]
2021-10-07 17:15:06.139 | DEBUG    | __main__:main:432 - 
***Evaluate models, feature: IAT+SIZE, header: False
2021-10-07 17:15:07.265 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.276 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.280 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.284 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.289 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.298 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.310 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.315 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.321 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.326 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.330 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.334 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.339 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.344 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.348 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.354 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.358 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.362 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.411 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.473 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.614 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.639 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.711 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.774 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.792 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.866 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.911 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.946 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.956 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:07.977 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.049 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.093 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.109 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.127 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.135 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.143 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.157 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.165 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.175 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.183 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.192 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.200 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.206 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.214 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.221 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.228 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.235 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.239 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.245 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.252 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.257 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.264 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.269 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.273 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.278 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.283 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.288 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.296 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.305 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.311 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.316 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.320 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.325 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.329 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.334 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.340 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.344 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.349 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.353 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.359 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.363 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.368 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.373 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.377 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.382 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.386 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.392 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.2 MiB    157.2 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.2 MiB      0.0 MiB           1   	try:
   381    157.2 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.2 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.2 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.2 MiB      0.0 MiB           1   	except Exception as e:
   407    157.2 MiB      0.0 MiB           1   		lg.error(e)
   408    157.2 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.394 | DEBUG    | __main__:main:439 - 
***Gather models
2021-10-07 17:15:08.394 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, OCSVM(rbf)]
2021-10-07 17:15:08.395 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, OCSVM(rbf)]
2021-10-07 17:15:08.396 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, KJL-OCSVM(linear)]
2021-10-07 17:15:08.397 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, KJL-OCSVM(linear)]
2021-10-07 17:15:08.397 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.397 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.398 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, KJL-GMM(full)]
2021-10-07 17:15:08.398 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, KJL-GMM(full)]
2021-10-07 17:15:08.398 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, KJL-GMM(diag)]
2021-10-07 17:15:08.399 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, KJL-GMM(diag)]
2021-10-07 17:15:08.399 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, Nystrom-GMM(full)]
2021-10-07 17:15:08.400 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, Nystrom-GMM(full)]
2021-10-07 17:15:08.400 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, Nystrom-GMM(diag)]
2021-10-07 17:15:08.400 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, Nystrom-GMM(diag)]
2021-10-07 17:15:08.401 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, KJL-QS-GMM(full)]
2021-10-07 17:15:08.401 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, KJL-QS-GMM(full)]
2021-10-07 17:15:08.402 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.402 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.402 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.403 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.403 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, UNB3_345, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.404 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, UNB3_345, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.405 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, OCSVM(rbf)]
2021-10-07 17:15:08.405 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, OCSVM(rbf)]
2021-10-07 17:15:08.405 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, KJL-OCSVM(linear)]
2021-10-07 17:15:08.405 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, KJL-OCSVM(linear)]
2021-10-07 17:15:08.406 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.406 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.406 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, KJL-GMM(full)]
2021-10-07 17:15:08.406 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, KJL-GMM(full)]
2021-10-07 17:15:08.406 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, KJL-GMM(diag)]
2021-10-07 17:15:08.407 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, KJL-GMM(diag)]
2021-10-07 17:15:08.407 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, Nystrom-GMM(full)]
2021-10-07 17:15:08.407 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, Nystrom-GMM(full)]
2021-10-07 17:15:08.407 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, Nystrom-GMM(diag)]
2021-10-07 17:15:08.408 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, Nystrom-GMM(diag)]
2021-10-07 17:15:08.408 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, KJL-QS-GMM(full)]
2021-10-07 17:15:08.408 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, KJL-QS-GMM(full)]
2021-10-07 17:15:08.408 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.408 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.409 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.409 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.409 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, CTU1, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.409 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, CTU1, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.410 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, OCSVM(rbf)]
2021-10-07 17:15:08.410 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, OCSVM(rbf)]
2021-10-07 17:15:08.410 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.410 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.411 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.411 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.412 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, KJL-GMM(full)]
2021-10-07 17:15:08.412 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, KJL-GMM(full)]
2021-10-07 17:15:08.413 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.413 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.414 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.414 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.414 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.415 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.415 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.415 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.416 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.416 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.416 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.417 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.417 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, MAWI1_2020, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.417 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, MAWI1_2020, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.417 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, OCSVM(rbf)]
2021-10-07 17:15:08.418 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, OCSVM(rbf)]
2021-10-07 17:15:08.418 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, KJL-OCSVM(linear)]
2021-10-07 17:15:08.418 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, KJL-OCSVM(linear)]
2021-10-07 17:15:08.419 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.419 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.420 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, KJL-GMM(full)]
2021-10-07 17:15:08.421 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, KJL-GMM(full)]
2021-10-07 17:15:08.421 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, KJL-GMM(diag)]
2021-10-07 17:15:08.421 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, KJL-GMM(diag)]
2021-10-07 17:15:08.422 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, Nystrom-GMM(full)]
2021-10-07 17:15:08.422 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, Nystrom-GMM(full)]
2021-10-07 17:15:08.422 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, Nystrom-GMM(diag)]
2021-10-07 17:15:08.422 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, Nystrom-GMM(diag)]
2021-10-07 17:15:08.423 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, KJL-QS-GMM(full)]
2021-10-07 17:15:08.423 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, KJL-QS-GMM(full)]
2021-10-07 17:15:08.423 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.424 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.424 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.424 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.425 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, MACCDC1, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.425 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, MACCDC1, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.425 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, OCSVM(rbf)]
2021-10-07 17:15:08.426 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, OCSVM(rbf)]
2021-10-07 17:15:08.426 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, KJL-OCSVM(linear)]
2021-10-07 17:15:08.427 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, KJL-OCSVM(linear)]
2021-10-07 17:15:08.427 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.428 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.428 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, KJL-GMM(full)]
2021-10-07 17:15:08.429 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, KJL-GMM(full)]
2021-10-07 17:15:08.429 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, KJL-GMM(diag)]
2021-10-07 17:15:08.430 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, KJL-GMM(diag)]
2021-10-07 17:15:08.430 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, Nystrom-GMM(full)]
2021-10-07 17:15:08.430 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, Nystrom-GMM(full)]
2021-10-07 17:15:08.431 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, Nystrom-GMM(diag)]
2021-10-07 17:15:08.431 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, Nystrom-GMM(diag)]
2021-10-07 17:15:08.431 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, KJL-QS-GMM(full)]
2021-10-07 17:15:08.432 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, KJL-QS-GMM(full)]
2021-10-07 17:15:08.432 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.432 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.433 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.433 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.434 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, SFRIG1_2021, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.434 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, SFRIG1_2021, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.434 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, OCSVM(rbf)]
2021-10-07 17:15:08.435 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, OCSVM(rbf)]
2021-10-07 17:15:08.435 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.435 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.437 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.437 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.438 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, KJL-GMM(full)]
2021-10-07 17:15:08.438 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, KJL-GMM(full)]
2021-10-07 17:15:08.438 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.439 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.439 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.439 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.440 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.440 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.440 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.441 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.441 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.441 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.441 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.442 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.442 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, AECHO1_2020, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.442 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, AECHO1_2020, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.443 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, OCSVM(rbf)]
2021-10-07 17:15:08.443 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/OCSVM(rbf)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, OCSVM(rbf)]
2021-10-07 17:15:08.444 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.444 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.445 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.445 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.446 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, KJL-GMM(full)]
2021-10-07 17:15:08.446 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, KJL-GMM(full)]
2021-10-07 17:15:08.446 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.447 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.447 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.447 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.448 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.448 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.448 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.449 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.449 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.449 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/KJL-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.450 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.450 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.451 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [False, False, IAT+SIZE, DWSHR_AECHO_2020, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.451 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/IAT+SIZE/header_False/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [False, True, IAT+SIZE, DWSHR_AECHO_2020, Nystrom-QS-GMM(diag)]
Function 'gather' executed in 0.0595s
2021-10-07 17:15:08.453 | INFO     | __main__:main:443 - examples/offline/deployment/out/src_dst_tmp/results/2021-10-07 17:15:02.288605/IAT+SIZE-header_False/gather-all.csv
2021-10-07 17:15:08.454 | DEBUG    | __main__:main:432 - 
***Evaluate models, feature: STATS, header: True
2021-10-07 17:15:08.457 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.464 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.471 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.496 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.511 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.518 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.529 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.536 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.541 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.547 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.555 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/UNB3_345/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.561 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.567 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.575 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.581 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.587 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.593 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.599 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.605 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.611 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.617 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.622 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/CTU1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.627 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.634 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.638 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.642 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.646 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.650 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.657 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.661 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.665 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.671 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.674 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.678 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.683 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.687 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.690 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.695 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.698 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.702 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.706 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.709 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.713 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.717 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/MACCDC1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.720 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.724 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.728 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.732 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.736 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.739 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.744 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.747 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.752 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.757 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.762 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.771 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.777 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.782 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.787 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.792 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.800 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.807 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.817 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.821 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.827 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.834 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.840 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/OCSVM(rbf)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.847 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.855 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.861 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.866 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.870 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.873 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.877 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.881 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.885 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.888 | ERROR    | __main__:_single_evaluate:407 - [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Traceback (most recent call last):
  File "examples/offline/deployment/deploy_evaluate_model_memory_profile.py", line 383, in _single_evaluate
    test_set = load(test_file)
  File "/Users/kunyang/PycharmProjects/kjl/kjl/utils/tool.py", line 49, in load
    with open(in_file, 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'examples/offline/deployment/data/src_dst/models/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/test_set.dat'
Filename: examples/offline/deployment/deploy_evaluate_model_memory_profile.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
   378    157.3 MiB    157.3 MiB           1   @profile
   379                                         def _single_evaluate(in_dir, out_dir, dataset, feature, header, model, tuning, n_repeats, n_test_repeats):
   380    157.3 MiB      0.0 MiB           1   	try:
   381    157.3 MiB      0.0 MiB           1   		test_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   382    157.3 MiB      0.0 MiB           1   		                         f'test_set.dat')
   383    157.3 MiB      0.0 MiB           1   		test_set = load(test_file)
   384                                         		history = {}
   385                                         		for i in range(n_repeats):
   386                                         			model_params_file = os.path.join(in_dir, dataset, feature, f'header_{header}', model,
   387                                         			                                 f'tuning_{tuning}',
   388                                         			                                 f'model_params_{i}th.dat')
   389                                         			params = load(model_params_file)
   390                                         			reconstructed_model = reconstruct_model(params)
   391                                         			# 3. Evaluate new models
   392                                         			out_ = _evaluate(reconstructed_model, test_set, n_test_repeats)
   393                                         			# out = minimal_model_cost(model_params_file, test_set, n_test_repeats)
   394                                         			args = Args(
   395                                         				{'dataset': dataset, 'feature': feature, 'header': header, 'model': model, 'tuning': tuning})
   396                                         			history[f'{i}th_repeat'] = {'args': args, 'train': params['extra_params']['train'],
   397                                         			                            'val': '', 'test': out_,
   398                                         			                            'space': params['space']}
   399                                         
   400                                         		out_file = os.path.join(out_dir, dataset, feature, f'header_{header}', model, f'tuning_{tuning}',
   401                                         		                        f'res.dat')
   402                                         		check_path(out_file)
   403                                         		dump(history, out_file)
   404                                         		out_file = os.path.splitext(out_file)[0] + '.csv'
   405                                         		save_dict2txt(history, out_file)
   406    157.3 MiB      0.0 MiB           1   	except Exception as e:
   407    157.3 MiB      0.0 MiB           1   		lg.error(e)
   408    157.3 MiB      0.0 MiB           1   		traceback.print_exc()


2021-10-07 17:15:08.890 | DEBUG    | __main__:main:439 - 
***Gather models
2021-10-07 17:15:08.890 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, OCSVM(rbf)]
2021-10-07 17:15:08.891 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, OCSVM(rbf)]
2021-10-07 17:15:08.891 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, KJL-OCSVM(linear)]
2021-10-07 17:15:08.891 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, KJL-OCSVM(linear)]
2021-10-07 17:15:08.892 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.892 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.892 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, KJL-GMM(full)]
2021-10-07 17:15:08.892 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, KJL-GMM(full)]
2021-10-07 17:15:08.892 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, KJL-GMM(diag)]
2021-10-07 17:15:08.893 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, KJL-GMM(diag)]
2021-10-07 17:15:08.893 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, Nystrom-GMM(full)]
2021-10-07 17:15:08.893 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, Nystrom-GMM(full)]
2021-10-07 17:15:08.893 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, Nystrom-GMM(diag)]
2021-10-07 17:15:08.894 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, Nystrom-GMM(diag)]
2021-10-07 17:15:08.894 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, KJL-QS-GMM(full)]
2021-10-07 17:15:08.894 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, KJL-QS-GMM(full)]
2021-10-07 17:15:08.894 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.894 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.895 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.895 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.895 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, UNB3_345, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.895 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/UNB3_345/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, UNB3_345, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.896 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv'. [True, False, STATS, CTU1, OCSVM(rbf)]
2021-10-07 17:15:08.896 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv'. [True, True, STATS, CTU1, OCSVM(rbf)]
2021-10-07 17:15:08.896 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, CTU1, KJL-OCSVM(linear)]
2021-10-07 17:15:08.896 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, CTU1, KJL-OCSVM(linear)]
2021-10-07 17:15:08.896 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, CTU1, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.897 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, CTU1, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.897 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv'. [True, False, STATS, CTU1, KJL-GMM(full)]
2021-10-07 17:15:08.897 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv'. [True, True, STATS, CTU1, KJL-GMM(full)]
2021-10-07 17:15:08.897 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, CTU1, KJL-GMM(diag)]
2021-10-07 17:15:08.897 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, CTU1, KJL-GMM(diag)]
2021-10-07 17:15:08.898 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv'. [True, False, STATS, CTU1, Nystrom-GMM(full)]
2021-10-07 17:15:08.898 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv'. [True, True, STATS, CTU1, Nystrom-GMM(full)]
2021-10-07 17:15:08.898 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, CTU1, Nystrom-GMM(diag)]
2021-10-07 17:15:08.898 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, CTU1, Nystrom-GMM(diag)]
2021-10-07 17:15:08.899 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, CTU1, KJL-QS-GMM(full)]
2021-10-07 17:15:08.899 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, CTU1, KJL-QS-GMM(full)]
2021-10-07 17:15:08.899 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, CTU1, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.899 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, CTU1, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.899 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, CTU1, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.900 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, CTU1, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.900 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, CTU1, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.900 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/CTU1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, CTU1, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.900 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, OCSVM(rbf)]
2021-10-07 17:15:08.900 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, OCSVM(rbf)]
2021-10-07 17:15:08.901 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.901 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.901 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.901 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.901 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, KJL-GMM(full)]
2021-10-07 17:15:08.902 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, KJL-GMM(full)]
2021-10-07 17:15:08.902 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.902 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.902 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.902 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.903 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.903 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.903 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.903 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.904 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.904 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.904 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.904 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.905 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, MAWI1_2020, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.905 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MAWI1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, MAWI1_2020, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.905 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, OCSVM(rbf)]
2021-10-07 17:15:08.905 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, OCSVM(rbf)]
2021-10-07 17:15:08.905 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, KJL-OCSVM(linear)]
2021-10-07 17:15:08.906 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, KJL-OCSVM(linear)]
2021-10-07 17:15:08.906 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.906 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.906 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, KJL-GMM(full)]
2021-10-07 17:15:08.907 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, KJL-GMM(full)]
2021-10-07 17:15:08.907 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, KJL-GMM(diag)]
2021-10-07 17:15:08.907 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, KJL-GMM(diag)]
2021-10-07 17:15:08.907 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, Nystrom-GMM(full)]
2021-10-07 17:15:08.907 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, Nystrom-GMM(full)]
2021-10-07 17:15:08.908 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, Nystrom-GMM(diag)]
2021-10-07 17:15:08.908 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, Nystrom-GMM(diag)]
2021-10-07 17:15:08.908 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, KJL-QS-GMM(full)]
2021-10-07 17:15:08.908 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, KJL-QS-GMM(full)]
2021-10-07 17:15:08.908 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.909 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.909 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.909 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.909 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, MACCDC1, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.909 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/MACCDC1/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, MACCDC1, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.910 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, OCSVM(rbf)]
2021-10-07 17:15:08.910 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, OCSVM(rbf)]
2021-10-07 17:15:08.910 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, KJL-OCSVM(linear)]
2021-10-07 17:15:08.910 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, KJL-OCSVM(linear)]
2021-10-07 17:15:08.910 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.911 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.911 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, KJL-GMM(full)]
2021-10-07 17:15:08.911 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, KJL-GMM(full)]
2021-10-07 17:15:08.911 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, KJL-GMM(diag)]
2021-10-07 17:15:08.911 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, KJL-GMM(diag)]
2021-10-07 17:15:08.912 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, Nystrom-GMM(full)]
2021-10-07 17:15:08.912 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, Nystrom-GMM(full)]
2021-10-07 17:15:08.912 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, Nystrom-GMM(diag)]
2021-10-07 17:15:08.913 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, Nystrom-GMM(diag)]
2021-10-07 17:15:08.913 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, KJL-QS-GMM(full)]
2021-10-07 17:15:08.913 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, KJL-QS-GMM(full)]
2021-10-07 17:15:08.913 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.913 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.914 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.914 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.914 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, SFRIG1_2021, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.914 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/SFRIG1_2021/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, SFRIG1_2021, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.914 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, OCSVM(rbf)]
2021-10-07 17:15:08.915 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, OCSVM(rbf)]
2021-10-07 17:15:08.915 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.915 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.915 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.915 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.916 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, KJL-GMM(full)]
2021-10-07 17:15:08.916 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, KJL-GMM(full)]
2021-10-07 17:15:08.916 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.916 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.916 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.917 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.917 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.917 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.917 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.918 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.918 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.918 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.918 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.918 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.919 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, AECHO1_2020, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.919 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/AECHO1_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, AECHO1_2020, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.919 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/OCSVM(rbf)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, OCSVM(rbf)]
2021-10-07 17:15:08.919 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/OCSVM(rbf)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, OCSVM(rbf)]
2021-10-07 17:15:08.920 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.920 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, KJL-OCSVM(linear)]
2021-10-07 17:15:08.920 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.920 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-OCSVM(linear)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, Nystrom-OCSVM(linear)]
2021-10-07 17:15:08.921 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(full)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, KJL-GMM(full)]
2021-10-07 17:15:08.921 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(full)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, KJL-GMM(full)]
2021-10-07 17:15:08.921 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.921 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, KJL-GMM(diag)]
2021-10-07 17:15:08.921 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(full)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.922 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(full)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, Nystrom-GMM(full)]
2021-10-07 17:15:08.922 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.922 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, Nystrom-GMM(diag)]
2021-10-07 17:15:08.922 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.922 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, KJL-QS-GMM(full)]
2021-10-07 17:15:08.923 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.923 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/KJL-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, KJL-QS-GMM(diag)]
2021-10-07 17:15:08.923 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.923 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(full)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, Nystrom-QS-GMM(full)]
2021-10-07 17:15:08.923 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_False/res.csv'. [True, False, STATS, DWSHR_AECHO_2020, Nystrom-QS-GMM(diag)]
2021-10-07 17:15:08.924 | ERROR    | examples.offline._gather:gather:44 - Error: [Errno 2] File b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv' does not exist: b'examples/offline/deployment/out/src_dst_tmp/DWSHR_AECHO_2020/STATS/header_True/Nystrom-QS-GMM(diag)/tuning_True/res.csv'. [True, True, STATS, DWSHR_AECHO_2020, Nystrom-QS-GMM(diag)]
Function 'gather' executed in 0.0343s
2021-10-07 17:15:08.924 | INFO     | __main__:main:443 - examples/offline/deployment/out/src_dst_tmp/results/2021-10-07 17:15:02.288605/STATS-header_True/gather-all.csv
Function 'main' executed in 2.7860s
